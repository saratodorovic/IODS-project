  
# Week 6: Analysis of Longitudinal Data

### *Description of the exercise phases and interpretation of the results*  

## Part 1: Data  
### Data description  

This week's theme is longitudinal data, which is the name for data that has repeated measures; if a response variable is measured under different conditions over different times on a same individual/subject, it is called longitudinal data. This kind of data helps to understand the data by identifying the observations as individuals, and data type occurs most frequently in for example psychological testing, when a subject is tested over a certain  time. The data and literature used for this week's exercise is produced by Kimmo Vehkalahti [(Vehkalahti and Everitt, 2019)](https://www.crcpress.com/Multivariate-Analysis-for-the-Behavioral-Sciences-Second-Edition/Vehkalahti-Everitt/p/book/9780815385158), and I will explore the datasets with help from Chapters 8 & 9 from the book.  

The first data is from a study by Crowder and Hand (1990), in which they examined nutrition of three groups of rats that were put on different diets, and each animal's body weight in grams was recorder over a nine-week period (Vehkalahti and Everitt, 2019, Chapter 9). Here the column 'rats' means weights in grams.  

Second BPRS data, by Davis (2002) is a study in which 40 males were assigned to two different treatments and observed once a week for eight weeks and given a brief psychiatric rating score (BPRS), which assesses the level of 18 symptom constructs such as hostility, suspiciousness, hallucinations and grandiosity; each of these is rated from one (not present) to seven (extremely severe).The scale is used to evaluate patients suspected of having schizophrenia (source: DataCamp).  

These two datasets have been converted from *wide* form into *longitudinal* form.  

Next I present the structure and summaries of the datasets:  

```{r}
# Reading the data

BPRS <- read.csv("~/Documents/GitHub/IODS-project/data/BPRSL.csv", sep = ",", header = TRUE, row.names = 1)
RATS <- read.csv("~/Documents/GitHub/IODS-project/data/RATSL.csv", sep = ",", header = TRUE, row.names = 1)
head(RATS)
head(BPRS)
str(RATS)
str(BPRS)
summary(RATS)
summary(BPRS)
```    

## Part 2: RATS  
#### Part 2 examines the **RATS** data by applying analyses from MABS (Vehkalahti and Everitt, 2019) Chapter 8: Analysis of Longitudinal Data I: Graphical Displays and Summary Measure Approach.  

### Graphical display  
First I will show a graphical display of the individual response profiles before and after standardization.  

```{r include=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(lme4)
```

```{r}

# Draw the plot RATS
ggplot(RATS, aes(x = Time, y = rats, linetype = as.factor(ID))) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(RATS$rats), max(RATS$rats))) 

```   

We see that in each group almost all individuals follow the same curve, which goes first up, and then decreases to almost same levels as in the beginning. We can also note that there are big weight differences between all groups, increasing by group number. There is also one significant outlier in the second group. Also we note that rats who are heavier in the beginning also have higher scores in the end, a phenomenon called tracking (Vehkalahti and Everitt, 2019, Chapter 8). Tracking can be better seen from standardized data below. 


```{r}
# Standardizing bprs values
RATSS <- RATS %>%
  group_by(Time) %>%
  mutate(stdrats = (rats - mean(rats))/sd(rats) ) %>%
  ungroup()
# Plot
ggplot(RATSS, aes(x = Time, y = stdrats, linetype = as.factor(ID))) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  scale_y_continuous(name = "standardized weight")
```   

In order to better understand the data, it is useful to calculate mean profiles for each group and compare them with each other. Choosing a summary method depends on the question of interest. I will present simple summaries with next two plots. This is done below by calculating the mean and standard error, for variation, for each treatment group:  


```{r}
# Calculating mean and standard error
# Length of time
RATS$Group <- factor(RATS$Group)
n <- RATS$Time %>% unique() %>% length()
# Summarizing
RATSsum <- RATS %>%
  group_by(Group, Time) %>%
  summarise( mean = mean(rats), se = sd(rats/sqrt(n)) ) %>%
  ungroup()

# Plot the mean profiles
ggplot(RATSsum, aes(x = Time, y = mean, linetype = as.factor(Group), shape = as.factor(Group))) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  scale_y_continuous(name = "mean(rats) +/- se(rats)") 

```   

In the summary profile we see that the groups are quite different from each other, with greatest variation (standard error) in the second group, highest values in the third group and lowest values with smallest standard error in the first group. Clearly the diet made the rats just fatter over time. Next, in order to compare the groups with each other better, I will draw boxplots to spot outliers and remove them so it won't bias the further comparisons.  



```{r}
# Summary
RATStime <- RATS %>%
  filter(Time > 1) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(rats) ) %>%
  ungroup()

ggplot(RATStime, aes(x = Group, y = mean, )) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(rats), days")

```  


We can see from the boxplots above that in each group there is one outlier. I will try to remove at least two of them and see what kind of difference it makes.  


```{r}
RATStime1 <- filter(RATStime, mean > 250 & mean < 550)

ggplot(RATStime1, aes(x = Group, y = mean, )) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(rats), days")
```   


I removed two of the outliers, which decreased the variance withing the groups, but no real evidence of the changes. Next I will run a t-test and calculate confidence intervals on the data to assess differences. Since there are three groups, I will use ANOVA to find out if there is any significant difference between the average weights of rats. In the Data Camp a two-sided t-test was performed, but since there are three groups, I found using ANOVA suits best.  


```{r}

res.aov <- aov(mean ~ Group, data = RATStime1)
# Summary of the analysis
summary(res.aov)

```  
Not surprisingly, there is significant difference between the means. This is still very shallow and simple graphical analysis of the observations, and requires deeper digging. 



## Part 3: BPRS 
#### Part 2 examines the **BPRS** data by applying analyses from MABS (Vehkalahti and Everitt, 2019) Chapter 9: Analysis of Longitudinal Data II: Linear Mixed Effects Models for Normal Response Variables. We will use linear mixed models to examine the correlations in the data. Like with the RATS-data, with BPRS data we also ignore that there are multiple observations of same people.


```{r}
ggplot(BPRS, aes(x = week, y = bprs, linetype = as.factor(subject))) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ treatment, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(BPRS$bprs), max(BPRS$bprs))) 
```  
Next I will fit a regression model by still ignoring the repeated-measures structure:  
```{r}
# create a regression model BPRS_reg
BPRS_reg <- lm(bprs ~ week + treatment, data = BPRS)
summary(BPRS_reg)
```  

We can see that treatment groups have no statistical significance, however the time variable 'week' has.  Next a more formal analysis is to fit a random intercept model for the explanatory variables treatment and week. This allows the linear regression fit for each man to differ in intercept from other men, by introducing random effects to subjects.  

```{r}

# Create a random intercept model
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRS, REML = FALSE)
summary(BPRS_ref)
```  
Results of the random intercept model are above. We can see, for example, that the variability of a single subject (man) is 6.885. Finally I will fit a random intercept and andom slope model. It allows the linear regression fits for each individual in the data to differ in intercept but also in slope. This way it is possible to account for the individual differences in the men's bprs values, but also the effect of time (Source: DataCamp). So in the next summary we see the differences in the men's bprs value change and the effect of time.  

```{r}
# create a random intercept and random slope model
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRS, REML = FALSE)
#Summary of the model
summary(BPRS_ref1)
# ANOVA test
anova(BPRS_ref1, BPRS_ref)
```  
From the ANOVA-test results we can see that the p value of the likelihood test between BPRS_ref1 (intercept) and BPRS_ref1 (slope) is 0.026 and significant in 99 % confidence level. The lower the value, the better the fit of the model.  

Last model allows the interaction between the treatment variable and week variable, and it is a random intercept and slope model. 

```{r}
BPRS_ref2 <- lmer(bprs ~ week * treatment + (week | subject), data = BPRS, REML = FALSE)
summary(BPRS_ref2)
anova(BPRS_ref2, BPRS_ref1)
```  
According to the ANOVA-test, week x treatment interaction is not statistically significant.  








